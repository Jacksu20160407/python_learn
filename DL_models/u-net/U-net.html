<!DOCTYPE html><html><head><title>U-net</title><meta charset='utf-8'><link href='https://dn-maxiang.qbox.me/res-min/themes/marxico.css' rel='stylesheet'><style>
.note-content  {font-family: "Helvetica Neue", Arial, "Hiragino Sans GB", STHeiti, "Microsoft YaHei", "WenQuanYi Micro Hei", SimSun, Song, sans-serif;}

</style></head><body><div id='preview-contents' class='note-content'>
                        
                    



<h1 id="u-net">U-net</h1>

<p><strong>Abstract</strong> <br>
一般认为成功训练一个深度网络需要上千个标记的训练样本。本文给出了一个新的网络结构和策略，这种策略依靠数据增强能够更加高效的使用标记样本。这种网络结构包括一个用于获取上下文信息的contracting部分和能够进行经确定位的expanding部分，两者呈对称结构。另外这个网络是个端到端的，分割非常快，一种512*512的图像在GPU上分割少于1秒。 <br>
<strong>1.</strong> <br>
深度卷积网络很早就出现，但是由于训练样本数量太少和对应的网络结构难以训练的限制，深度卷积网络一直没有成功。2012年的Alex Net 有8层，一百万个参数的训练打破了这个限制。 <br>
CNN一般用于分类，但是对于像生物医学图像处理还需要定位，并且上大量的生物医学图像很难获得。 <br>
之前有人进行patch级别的像素分类和定位。但是这样有两个缺点：（1）非常慢，因为每个patch需要单独训练测试，并且由于patch之间的重叠使得数据冗余。（2）需要在定位精度和上下文信息之间做出权衡，因为大的patch需要很多的max-pooling，这就损失了定位精度，小的patch就损失了上下文信息。 <br>
本文中设计了一个更加简洁的FCN网络。对FCN进行了改进和扩展，具体可以查看<img src="!%5BAlt%20text%5D%28./1523278348911.png%29" alt="enter image description here" title=""> <br>
。主要思想就是增加一个constracting 网络结构，并用上采样代替pooling操作。这个结构的主要作用就是增加输出的分辨率。为了使用局部信息，在网络收缩过程中产生的高分辨率特征，被连接到了修改后网络的上采样的结果上。基于这些信息，连续的卷积层能够学习到更加精确地输出。 <br>
与FCN相比，文中的上采样部分同样有大量的特征通道，这就能将上下文信息传播到高层。（这里的意思是不是expanding部分都采用了反卷积，相对于FCN只是将最后的全连接部分改成了反卷积）<strong>U-net只使用了每一个卷积的有效部分，并没有使用全连接层，也就是说分割图（特征图？？）只包含能够从输入图像中获得上下文信息的像素点（？？）。</strong>这个策略通过一个重叠片方法能够对任意大小的图像进行无损分割， <br>
重叠片方法可以查看<img src="/hhh.png" alt="hhh" title="">。对于图像边界区域的预测是通过对输入图像做镜像对称获得丢失的上下文信息的。这个方法对于网络大的输入图像非常重要，因为如果不这样的话分辨率将会受到GPU内存的限制（？？）。 <br>
由于训练数据非常少，所以需要利用弹性形变方法对训练数据进行数据增强，这能够使网络学习到对各种形变的不变性。这对于生物医学图像非常有用，因为生物医学图像存在非常多的形变，通过数据增强能够有效地模拟实际中的这种形变。 <br>
<strong>细胞分割分割的另一个难点是同类目标的黏连，为此，本文建议使用加权的损失函数，也就是在黏连细胞之间分割的背景在损失函数中获得大的权重。</strong> <br>
<strong>2.网络结构</strong> <br>
网络结构由收缩路径（左边的部分）和扩张路径（右边的部分）组成。收缩路径遵循典型的卷积网络结构，包括多个重复出现的3X3的卷积（没有padding），每个卷积后面是一个Relu和一个用于下采样的2X2的最大池化层，池化步长为2。每经过一个下采样特征通道就加倍。扩张路径的每一步都包括上采样层，上采样后面是一个2X2的卷积层（上采样+卷积？=反卷积，整体思想就是扩大特征图的分辨率，减少特征图的数量），将得到的结果和收缩路径中对应的特征图连接到一起（收缩路径中的特征图偏大，需要crop），之后就是两个3X3的卷积和Relu层。最后是一个1X1的卷积用于将每一个64通道的特征向量映射到所需的特征类数量。这个网络总共包括23个卷积层。 <br>
<strong>3.训练</strong> <br>
使用随机梯度下降法训练，在Caffe框架下实现。动量设置为0.99，所以之前的训练样本对当前优化更新起着很重要的作用。 <br>
在最后的特征图上使用像素级的soft-max和交叉熵。交叉熵惩罚每一个位置相对于1的偏差。交叉熵中的权值<span xmlns="http://www.w3.org/1999/xhtml" class="" rel="8dd7c1546ab5aec49d0b95c5356c61bd"><span class="MathJax_SVG" id="MathJax-Element-14-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span><img type="image/png" width="33.9688" height="17.9844" longdesc="__SVG__undefined" src="data:image/png;base64,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" style="margin-top:0;margin-bottom:0;"></span></span></span>在训练过程中改变一些像素的重要性。 <br>
为了补偿训练集中某一类像素的频率差异（i.e. 粘连的细胞之间的背景像素频率很少），我们为每一个金标准分割图制作了权值图，这就强迫网络去学习我们之前介绍的粘连细胞之间的小的分离边界。 <br>
分割边界是通过形态学操作获得的。权值图是通过以下公式获得：</p>



<p><img src="quanzhi.png" alt="quanzhi" title=""> <br>
wc是用于平衡类别频率的权值图，d1:代表到最近的细胞边界的距离，d2:代表到第二近细胞边界的距离。w0和σ为常数，试验中设置w0=10，σ=5个像素。 <br>
深度学习中好的初始化权值非常重要，否则网络的一部分被过度激活，其他部分却没有起作用。理想状态的初始权值是网络中每一个特征图都有近似的单位方差。我们使用的初始权值为标准差为<strong>根下2N</strong>的高斯分布，N为每个神经元的输入节点数量。例如，对于一个上一层是64通道的3*3卷积核来说，N=9*64=576 <br>
<strong>3.1 数据增强</strong> <br>
当使用很少的标记样本训练一个分割网络的时候，训练样本的随机弹性形变回一个很关键的概念。在一个3X3的粗糙网格上使用随机位移矢量生成光滑形变。位移从10个像素的标准差的高斯分布中取样。每一个位移使用<a href="https://en.wikipedia.org/wiki/Bicubic_interpolation" target="_blank">双三次插值</a>计算获得。网络结构的最后使用Drop-out近一步执行隐式的数据增强。 <br>
<strong>4.实验</strong> <br>
训练集是30张512X512的神经元结构图。细胞是白色，细胞膜是黑色，测试集公开，但是测试集的分割mask是保密的。你需要将预测细胞膜的概率图发给组织方，组织方使用10种不同的阈值进行评价，并计算”warping error”等多误差。 <br>
U-net在没有进行预处理和后处理的情况下，实现warping误差0.0003529。 <br>
另外在“PHC”数据集上，有35张部分标记的训练图像。U-net的平均IOU是92%。在“DIC”上，有20张部分标记的训练图像，U-net的平均IOU是77.5%。 <br>
<strong>5.总结</strong> <br>
U-net在不同的生物医学图像分割应用上都取得了很好的性能。多亏弹性形变的数据增强方法，U-net训练只需要很少的标记图像并且在NVidia Titan GPU（6G）上只花费了10个小时。</p></div></body></html>